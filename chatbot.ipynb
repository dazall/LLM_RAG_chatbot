{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "api_key = \"your api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm  = ChatGroq(groq_api_key = api_key, model_name = \"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm assuming you're referring to \"Maggi\" which is a popular instant noodle brand. Here's a simple recipe to make Maggi noodles with a flavorful twist:\n",
      "\n",
      "**Ingredients:**\n",
      "\n",
      "- 1 packet of Maggi noodles\n",
      "- 2 cups of water\n",
      "- 1 tablespoon of oil (vegetable or peanut oil)\n",
      "- 1 small onion, finely chopped\n",
      "- 2 cloves of garlic, minced\n",
      "- 1 small tomato, diced\n",
      "- 1 teaspoon of chili flakes (optional)\n",
      "- 1 teaspoon of soy sauce\n",
      "- Salt to taste\n",
      "- Your choice of garnish (e.g., chopped green onions, grated cheese, or a slice of lemon)\n",
      "\n",
      "**Instructions:**\n",
      "\n",
      "1. **Boil the water**: Boil 2 cups of water in a large saucepan.\n",
      "2. **Cook the noodles**: Add the Maggi noodles to the boiling water and cook according to the package instructions (usually 2-3 minutes). Drain the water and set the noodles aside.\n",
      "3. **Heat the oil**: In a separate saucepan, heat 1 tablespoon of oil over medium heat.\n",
      "4. **Sauté the onion and garlic**: Add the chopped onion and minced garlic to the oil and sauté until the onion is translucent.\n",
      "5. **Add the tomato**: Add the diced tomato to the saucepan and sauté for 1-2 minutes.\n",
      "6. **Add the chili flakes and soy sauce**: Add the chili flakes (if using) and soy sauce to the saucepan and stir well.\n",
      "7. **Combine the noodles and sauce**: Add the cooked noodles to the saucepan and toss well with the sauce.\n",
      "8. **Season with salt**: Add salt to taste and stir well.\n",
      "9. **Garnish**: Garnish with chopped green onions, grated cheese, or a slice of lemon.\n",
      "10. **Serve**: Serve the Maggi noodles hot and enjoy!\n",
      "\n",
      "**Tips and Variations:**\n",
      "\n",
      "- You can customize the recipe by adding your favorite vegetables (e.g., bell peppers, carrots, or mushrooms).\n",
      "- You can also use different types of oil (e.g., coconut oil or sesame oil) for a unique flavor.\n",
      "- If you prefer a spicy version, add more chili flakes or use hot sauce.\n",
      "- You can also add a fried egg or cooked chicken to make the dish more substantial.\n",
      "\n",
      "I hope you enjoy this recipe!\n"
     ]
    }
   ],
   "source": [
    "ans = llm.invoke(\"Write  receipy of maagi ?\")\n",
    "print(ans.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Sum of Two Numbers in Python**\n",
      "====================================\n",
      "\n",
      "Here's a simple Python function that takes two numbers as input and returns their sum.\n",
      "\n",
      "```python\n",
      "def sum_of_two_numbers(a, b):\n",
      "    \"\"\"\n",
      "    Returns the sum of two numbers.\n",
      "\n",
      "    Args:\n",
      "        a (float): The first number.\n",
      "        b (float): The second number.\n",
      "\n",
      "    Returns:\n",
      "        float: The sum of a and b.\n",
      "    \"\"\"\n",
      "    return a + b\n",
      "\n",
      "# Example usage:\n",
      "num1 = 5\n",
      "num2 = 10\n",
      "\n",
      "result = sum_of_two_numbers(num1, num2)\n",
      "print(f\"The sum of {num1} and {num2} is: {result}\")\n",
      "```\n",
      "\n",
      "In this code:\n",
      "\n",
      "*   We define a function `sum_of_two_numbers` that takes two arguments `a` and `b`.\n",
      "*   The function returns the sum of `a` and `b` using the `+` operator.\n",
      "*   We provide an example usage of the function, where we calculate the sum of `5` and `10` and print the result.\n",
      "\n",
      "**Tips:**\n",
      "\n",
      "*   Make sure to handle potential errors, such as non-numeric inputs or overflows.\n",
      "*   You can modify the function to accept a variable number of arguments using the `*args` syntax.\n",
      "*   Consider adding input validation and error handling to make your code more robust.\n"
     ]
    }
   ],
   "source": [
    "ans = llm.invoke(\"write python code for sum of 2 number\")\n",
    "print(ans.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(\n",
    "        file_path=\"codejay_chatbot_full_dataset.csv\",\n",
    "        source_column=\"Question\",\n",
    "        content_columns=[\"Answer\"],\n",
    "        metadata_columns=[\"Question\"],\n",
    "        encoding=\"utf-8\",\n",
    "        autodetect_encoding=True  # allow trying other encodings if UTF-8 fails\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaypr_ughx7yt\\Downloads\\Codejay_Chatbot\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings using the Hugging Face model\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedder.embed_query(\"This is a test document.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.038338545709848404,\n",
       " 0.1234646886587143,\n",
       " -0.028642931953072548,\n",
       " 0.05365271493792534,\n",
       " 0.008845364674925804]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FAISS instance for vector database from 'data'\n",
    "vectordb = FAISS.from_documents(documents=data, embedding=embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vector database locally\n",
    "vectordb.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever for querying the vector database\n",
    "retriever = vectordb.as_retriever(score_threshold = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaypr_ughx7yt\\AppData\\Local\\Temp\\ipykernel_29856\\4209023829.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  rdocs = retriever.get_relevant_documents(\"what is codejay\")\n"
     ]
    }
   ],
   "source": [
    "rdocs = retriever.get_relevant_documents(\"what is codejay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='33df6ade-e302-4989-ae44-e59b7667f9d8', metadata={'source': 'What is CodeJay?', 'row': 0, 'Question': 'What is CodeJay?'}, page_content='Answer: CodeJay is a YouTube channel that creates informative and project-based videos on data science, machine learning, artificial intelligence, and related technologies.'),\n",
       " Document(id='3e945bc2-8bcc-4633-8d7d-7078a823637b', metadata={'source': 'What type of videos does CodeJay make?', 'row': 1, 'Question': 'What type of videos does CodeJay make?'}, page_content='Answer: CodeJay produces videos on data science concepts, end-to-end machine learning projects, deep learning, NLP, and practical implementation tutorials.'),\n",
       " Document(id='7043c253-5a7a-4c40-aef5-edaedafd77ba', metadata={'source': 'Where can I find the CodeJay GitHub repository?', 'row': 19, 'Question': 'Where can I find the CodeJay GitHub repository?'}, page_content='Answer: The GitHub link is shared in each video description. You can also find it by searching \"CodeJay GitHub\" on Google.'),\n",
       " Document(id='d6614476-b3c5-4b8c-81f5-805a09907dfe', metadata={'source': 'Does CodeJay provide source code for projects?', 'row': 5, 'Question': 'Does CodeJay provide source code for projects?'}, page_content='Answer: Yes, we provide GitHub links to the source code in the video description.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create RetrievalQA chain along with prompt template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer. No Preamble.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                            chain_type=\"stuff\",\n",
    "                            retriever=retriever,\n",
    "                            input_key=\"query\",\n",
    "                            return_source_documents=True,\n",
    "                            chain_type_kwargs={\"prompt\": PROMPT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most of our projects can be run using Jupyter Notebook or Google Colab. We provide setup instructions in each video.\n"
     ]
    }
   ],
   "source": [
    "result = chain(\"How we can run our project on local system\")\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
